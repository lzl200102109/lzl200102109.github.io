<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
<title>Cyber-Physical Cloud Computing (CPCC)</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="description" content="This site was created from a template originally designed and developed by Codify Design Studio. Find more free templates at http://www.adobe.com/devnet/author_bios/chris_converse.html" />
<link rel="stylesheet" type="text/css" href="stylesheet.css" />
<script src="SpryAssets/SpryMenuBar.js" type="text/javascript"></script>
<link href="SpryAssets/SpryMenuBarHorizontal.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div class="bannerArea">
  <div class="container">
    <div class="bannernav"><a href="index.html" >Home</a> &bull; <a href="contact.html" >Contact</a></div>
    <div class="toplogo"><img src="images/banner_logo.gif" width="754" height="61" border="0"/></div>
    <div style="clear:both;"></div>
  </div>
</div>
<div class="topnavigationArea">
  <div class="container">
    <div class="topnavigationgroup">
      <ul id="MenuBar1" class="MenuBarHorizontal">
        <li><a href="index.html">Home</a></li>
        <li><a href="publications.html">Publications</a></li>
        <li><a href="projects.html">Projects</a></li>
        <li><a href="people.html">People</a></li>
        <li style="border-right-style: solid;"><a href="outreach.html">Outreach</a></li>
      </ul>
    </div>
    <div style="clear:both;"></div>
  </div>
</div>
<div class="contentArea">
  <div class="container">
    <div class="contentleft">
      <h1><a name="Top">Projects</a></h1>
      <p>
      <ul>
        <li> <a href="#SunilMasterProject">Drones: The Killer App (Master of Engineering Capstone Project) - May 16th, 2014</a>
        <li> <a href="#BayTrail">Aerial photography for the Bay Trail - March 28th, 2014</a>
        <li> <a href="#Delivery">Mail Delivery Demonstration - March 12th, 2014</a>
        <li> <a href="#Detect">UC Berkeley UAV Operated from an MBARI Vessel to Detect Oceanic Fronts - September 26th, 2012</a>
        <li> <a href="#Search">Flight test: Search and Track at Ota Air Base, Portugal - July 4th, 2012</a>
        <li> <a href="#SAM">CPCC Sense Act Move Platform</a>
        <li> <a href="#Simulator">CPCC Simulator</a>
        <li> <a href="#ROS">Robotic Operating System (ROS)</a>
        <li> <a href="#Sampling">CO<sub>2</sub> Concentration Sampling</a>
      </ul>
      
      <hr>
      <h2><a name="SunilMasterProject">Drones: The Killer App (Master of Engineering Capstone Project) - May 16th, 2014</a></h2>
      <p>CPCC and 3DRobotics co-advised a Master of Engineering capstone project for a group of four students from the IEOR and EECS departments. The project investigated potential commercial applications of UAV research with a view to the upcoming federally mandated regulatory change.</p>

      <p>

        <ol>
        
          <li><i>Intelligent path planning</i></li>

          <p>Optimisation techniques were used to produce a simple path planning interface that allows waypoint generation for a UAV while optimising for to several constraints such as wind direction, air resistance and fuel economy.  This capability is missing from current open source path planning tools.</p>


          <li><i>Real-time image processing on embedded computers</i></li>

          <p>By using parallel processing techniques and optimising generated code for ARM instruction set processors, we were able to achieve the maximum frame-rate possible using open source libraries and boards. This allows rapid prototyping of image processing applications. An EECS Master's report is available <a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-117.html">here</a>.</p>


          <li><i>Structural health monitoring</i></li>

          <p>It is hard to diagnose failure in multi-rotor UAVs at the moment. By attaching accelerometers to the UAV's frame and comparing live data against a known baseline, it is possible to detect mechanical failure - either as a pre-arm check or in-flight. We collected a set of data and, as part of a machine learning class project, were able to very accurate classify the UAV's structural health as erroneous or not. An EECS Master's report is available <a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-70.html/">here</a> and the machine learning class report is available <a href="http://pub.geekonabicycle.co.uk/cs289a/report.pdf">here</a>.</p>


        </ol>

      </p>
     
      <p> <img src="images/SunilMasterImage1.jpg" alt="" width="480" border="0"/> </p>
      <p> <img src="images/SunilMasterImage2.jpg" alt="" width="480" border="0"/> </p>
      <p> <img src="images/SunilMasterImage3.jpg" alt="" width="480" border="0"/> </p>
      <p> <img src="images/SunilMasterImage4.jpg" alt="" width="480" border="0"/> </p>


      
      <hr>
      <h2><a name="BayTrail">Aerial survey for the Lake Merritt to Bay Trail Connection - March 28th, 2014</a></h2>
      <p> In collaboration with UnmannedData, CPCC used multirotor UAVs to carry out aerial photography for Bay Area design firm Hood Design. Our photographs were used to present the proposed construction to the local community from a perspective that could not be captured through conventional photography. Hood Design are responsible for designing the connection between the Oakland Bay Trail and Lake Merritt, updates on their project are available <a href="http://www.lm2bt.com/">here</a>. <a href="http://www.baytrail.org/aboutus.html">The Bay Trail</a> is a biking and walking trail under construction that will eventually provide a 500 mile continuous route around the Bay.  </p>
     
      <p> <img src="images/BayTrail1.JPG" alt="" width="480" border="0"/> </p>
      <p> <img src="images/BayTrail2.JPG" alt="" width="480" border="0"/> </p>
      <p> <img src="images/BayTrail3.JPG" alt="" width="480" border="0"/> </p>
      <p> <img src="images/BayTrail4.JPG" alt="" width="480" border="0"/> </p>
      <p> <img src="images/BayTrail5.JPG" alt="" width="480" border="0"/> </p>
      <p> <img src="images/BayTrail6.JPG" alt="" width="480" border="0"/> </p>
      <p> <img src="images/BayTrail7.JPG" alt="" width="480" border="0"/> </p>
      <p> <img src="images/BayTrail8.JPG" alt="" width="480" border="0"/> </p>
      <p><a href="#Top">Back To Top</a> </p>
      
      
      
      
      
      <hr>
      <h2><a name="Delivery">Mail Delivery Demonstration - March 12th, 2014</a></h2>
      <p>This video presents a conceptual future mail delivery demonstration using quadrotor UAV. Professor Wathiq Mansoov from the Department of Computer Engineering at the American University in Dubai (AUD) visited our UAV lab on March 12, 2014. During his visit, our lab member Gita performed this indoor demonstration.</p>
      <iframe src="https://www.youtube.com/embed/c1YQW-2zMYA?feature=player_detailpage" width="500" height="281" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
      <p><a href="https://www.youtube.com/watch?v=c1YQW-2zMYA">Mail delivery demonstration at UAV lab at UC Berkeley</a>.</p>
      <p><a href="#Top">Back To Top</a> </p>
      
      
      <hr>
      <h2><a name="Detect">
Oil Spill Monitoring Exercise Using Networked Vehicles and Sensors, Portimão, Portugal - July, 2014</a></h2>
      <p>The video describes an environmental monitoring exercise using networked vehicles and sensors. The exercise consisted of searching for an ship that committed an environmental hazard better known as "bilge dumping" and monitoring the respective oil spill. The oil was recreated using 100 kg of popcorn which is know to have similar dynamics. The popcorn was deployed by a Navy vessel. A fixed-wing Unmanned Aerial Vehicle (UAV) equipped with a gimbaled EO camera and a Automatic Identification System (AIS) receiver was deployed to search the "oil" spill and the "suspected" ship. After the oil spill was detected, a message was sent to a Navy vessel that deployed four drifters over the spill in order to forecast its dynamics. The drifters were equipped with GPS and broadcast their position using AIS. The UAV received the AIS information and visited the drifters location to assess their effectiveness while forecasting the oil spill trajectory.</p>
      <iframe src="//player.vimeo.com/video/72699388" width="500" height="281" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe> <p><a href="http://vimeo.com/72699388">Oil Spill Monitoring Exercise Using Networked Vehicles and Sensors, Portimão, Portugal</a> from <a href="http://vimeo.com/user10774557">Eloi Pereira</a> on <a href="https://vimeo.com">Vimeo</a>.</p>
      <p><a href="#Top">Back To Top</a> </p>

      
      <hr>
      <h2><a name="Detect">UC Berkeley UAV Operated from an MBARI Vessel to Detect Oceanic Fronts - September 26th, 2012</a></h2>
      <p>This video presents a demonstration performed under the collaboration of UC Berkeley Cyber-Physical Cloud Computing (CPCC) Lab and the Monterrey Bay Area Research Institute (MBARI). The purpose of this experiment was to use a small Unmanned Aerial Vehicle (a Zephyr flying wing) launched from an MBARI Zephyr vessel to detect oceanic fronts. A front is formed at the boundary between two masses of water with different temperatures. Fronts are rich habitats for biological activity. This activity can be observed by filaments of foam at the surface. The onboard video shows a clear front that appeared to have several miles of length. The filament is visible as well as the different masses of water which appear with slightly different colors.</p>
      <iframe src="http://player.vimeo.com/video/54435401?badge=0" width="500" height="281" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
      <p><a href="http://vimeo.com/54435401">UC Berkeley UAV operated from an MBARI vessel to detect oceanic fronts</a> from <a href="http://vimeo.com/user10774557">Eloi Pereira</a> on <a href="http://vimeo.com">Vimeo</a>.</p>
      <p><a href="#Top">Back To Top</a> </p>
      
      
      <hr>
      <h2><a name="Search">Flight test: Search and Track at Ota Air Base, Portugal - July 4th, 2012</a></h2>
      <p>The video presents a flight test of the searching and tracking algorithm. The position of the target is unknown (for the sake of visualization we present the target as a blue circle). The target detection is abstracted using GPS and a model of a gimbaled camera. An operator defines a initial likelihood map of the target position. The present case shows the definition of a gaussian map with a given mean and variance. The UAV starts searching for the target steering towards the maximum of the a priori likelihood map. During searching, the likelihood map is updated regarding the sensor model, i.e. if the target is not detected under the sensor footprint the likelihood map is decreased to near zero, if the target is detected the likelihood map becomes a gaussian function with mean centered at the estimated target position and a variance that models the sensor resolution error. When the target is detected the algorithm switches to a tracking algorithm. The algorithm switches back to searching mode whenever the target gets outside the sensor's footprint. This work is a summer project performed by researchers from UC Berkeley (CPCC project - cpcc.berkeley.edu/), Academia da Força Aérea, and FEUP.</p>
      <iframe width="640" height="360" src="http://www.youtube.com/embed/sjAnC4WVPsE?feature=player_detailpage" frameborder="0" allowfullscreen></iframe>
      <p><a href="http://vimeo.com/45240958">Flight test: Search and Track at Ota Air Base, Portugal</a> from <a href="http://vimeo.com/user10774557">Eloi Pereira</a> on <a href="http://vimeo.com">Vimeo</a>.</p>
      <p><img class="imagemiddle" src="images/Hao_Ota.jpeg" alt="" height="239" border="0"/></p>
      <p><a href="#Top">Back To Top</a> </p>
      
      
      <hr>
      <h2><a name="SAM">CPCC Sense Act Move Platform</a></h2>
      <p>The CPCC Sense Act Move (SAM) platform provides the infrastructure to create so-called virtual vehicles (VV) that are capable of executing certain user-defined tasks. VVs are deployed into a cloud of real vehicles (RV) which provide execution platforms that may be moving in space. Furthermore, users are able to create a mapping plans that tells the system how VVs move across several RVs. The platform provides a website to control the system of RVs and VVs. The parts in more detail:</p>
      <p><b>Virtual Vehicles</b></p>
      <p>VVs are either created online, or programmed offline and uploaded to the platform. The specification language is JavaScript. Currently the capabilities of a VV include simple arithmetic calculations, access to sensor values, i.e. GPS position, access to a storage mechanism that is tied to the VV, and migration. The underlying infrastructure of VVs is designed to allow migration at any point in time, triggered by the user program. For example, if the program decides that it has captured enough sensor values at a certain position, it can decide to migrate onto a different RV.<img class="imagemiddle" src="images/Michael_CreateVV.png" alt="" height="239" border="0"/></p>
      <p><b>Real Vehicles</b></p>
      <p>RVs provide the execution platform that is facilitated by one or more VVs. An RV can host multiple VVs. Currently the RV is an Android phone hosting a CPCC application. As soon as a phone user registers an account with the platform, the phone is connected to the cloud and therefore a possible receiver of one or multiple VVs. While RVs are tied to an account, they act as completely anonymous computation providers in the cloud. In order to run VVs the RVs provide a JavaScript sandbox which is shipped with the Android application. Currently the VVs are isolated from each other in way that there is no direct access from one VV to another one. (They don't even know that other VVs are on the same RV). A VV migration triggers the RV to pack the complete sandbox state into a VV package and send it to a central server, where the mapping algorithm is triggered to a find a new RV (or the execution is terminated).</p>
      <p><img class="imagemiddle" src="images/Michael_Android.png" alt="" height="239" border="0"/></p>
      <p><b>Mapping plan</b></p>
      <p>Mapping algorithms specify how VVs migrate across different RVs. The specification language is JavaScript. The mapping algorithms can be used to force the execution of a VV to happen in a certain area, as the programs have access to the position of the RVs (in a regulated way). Another example would be that a group of RVs can be selected in a round-robin fashion, to avoid using some RV to often.</p>
      <p><a href="#Top">Back To Top</a> </p>
      <hr>
      <h2><a name="Simulator">CPCC Simulator</a></h2>
      <p>This <a href="http://cs.uni-salzburg.at/~ckrainer/CPCC">simulation system</a> demonstrates information-acquisition-as-a-service of mobile sensor networks for
        cyber-physical cloud computing (CPCC) as proposed in [1]. Based on the JNavigator project [2] the implementation provides</p>
      <p>(1) The simulation of physical helicopter swarms;</p>
      <p>(2) The simulation of sensors;</p>
      <p>(3) The virtual abstraction of autonomous vehicles (virtual vehicles);</p>
      <p>(4) The migration of virtual vehicles among flying physical helicopters (real vehicles).</p>
      <p>The implemented system currently allows the simulation of helicopter fleets of several dozens of vehicles and supports the simulation of sensors like GPS receivers and photo cameras. To simulate air-pressure sensors, temperature sensors, etc. the system utilizes random number generators, which deliver values in a defined range and precision.</p>
      <p>Simulated helicopters do not access the onboard sensors for data
        collection.  It is a virtual abstraction of autonomous vehicles,
        Virtual Vehicles (VVs) for short, that gathers data. One helicopter is able to carry several VVs. To complete their missions, VVs may migrate between helicopters.</p>
      <p>Demos of the CPCC Simulator can be found <a href="http://cs.uni-salzburg.at/~ckrainer/CPCC">here</a>.</p>
      <p>[1] Craciunas, S.S., Haas, A., Kirsch, C.M., Payer, H., ock, H., Rottmann, A., Sokolova, A., Trummer, R., Love, J., and Sengupta, R.:Information-acquisition-as-a-service for cyber-physical cloud computing. In Proc. Workshop on Hot Topics in Cloud Computing (HotCloud). USENIX, 2010.</p>
      <p>[2] Krainer, Clemens D.: JNavigator - An Autonomous Navigation System for the JAviator Quadrotor Helicopter. Master's thesis, University of Salzburg, Austria, 2009.</p>
      <p><a href="#Top">Back To Top</a> </p>
      <hr>
      <h2><a name="ROS">Robotic Operating System (ROS)</a></h2>
      <p>Our undergraduates have been working to use the Robotic Operating System (ROS) along with the AR Drone driver developed by Brown University in conjunction with OpenCV (open source C++ image processing library) to establish an easily deployable platform for testing multi-UAV algorithms. This platform has allowed for obtaining video stream through the AR Drone, processing the video, and using the results to control the AR Drone. Current work involves the use of this test bed for tracking a colored object using a single UAV. Future goals include the use of multiple automated drones to cooperatively complete a task.</p>
      <p><img class="imagemiddle" src="images/Abi_ImageProcessing.png" alt="" height="239" border="0"/></p>
      <p><img class="imagemiddle" src="images/Abi_TopicGraph.png" alt="" height="239" border="0"/></p>
      <p><a href="#Top">Back To Top</a> </p>
      <hr>
      <h2><a name="Sampling">CO<sub>2</sub> Concentration Sampling</a></h2>
      <p>This video presents a preliminary flight test of a flying wing UAV sampling CO<sub>2</sub> concentration in flight. The goal of the project is to create a mobile and easily deployable CO<sub>2</sub> senor network utilizing a team of inexpensive autonomous UAVs. As shown in the video, the UAV was equipped with an ardupilot-mega autopilot system and a k-30 CO<sub>2</sub> sensor.  The zephyr flying wing airframe used in the video is capable
        of carrying up to 1 pound of payload and has a max flight duration of 30 minutes. The ardupilot-mega autopilot is an inexpensive open
        source autopilot system capable of autonomous way point flights,
        flight by wire mode, and manual mode.  The k-30 CO<sub>2</sub> sensor used has a measurement range of 0-10,000 ppm and more information can be found on their website. The flight test was performed near Merritt College in Oakland, California and the aircraft was flown in manual mode.</p>
      <p>
        <iframe src="http://player.vimeo.com/video/43322242" width="500" height="275" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
      </p>
      <h2><a href="http://c3uv.berkeley.edu/index.php?id=videos" >More videos from C3UV</a>.</h2>
      <p><a href="#Top">Back To Top</a> </p>
    </div>
    <div class="contentright">
      <h2>Recent Publications</h2>
      <!--<p>J. Huang and R. Sengupta, Risk and Reward in Spatial Queuing Theory.<a href="papers/SQP1.pdf">[pdf]</a></p>
      <p>J. Huang and R. Sengupta, Management of Spatial Queuing Systems: The Case of Gated Policies.<a href="papers/SQP2.pdf">[pdf]</a></p>-->
      <p>C. Kirsch etc., Cyber-Physical Cloud Computing: The Binding and Migration Problem. <a href="papers/DATE12.pdf">[pdf]</a></p>
      <p>J. Love, Network-Level Control of Collaborative UAVs.<a href="papers/JoshuaLove.pdf">[pdf]</a></p>
      <p>S. Craciunas, J. Love etc., Information-Acquisition-as-a-Service for Cyber-Physical Cloud Computing.<a href="papers/HotCloud10.pdf">[pdf]</a></p>
      <p>J. Love etc., CSL: A Language to Specify and Re-Specify Mobile Sensor Network Behaviors.<a href="papers/CSL.pdf">[pdf]</a></p>
      <h2>Links</h2>
      <p><a href="http://c3uv.berkeley.edu/" >Center for Collaborative Control of Unmanned Vehicles (C3UV)</a></p>
      <p><a href="http://cs.uni-salzburg.at/~ck/group/" >The Computational Systems Group at the University of Salzburg</a></p>
      <p><a href="http://vehicle.me.berkeley.edu/" >Vehicle Dynamics and Control Lab (VDL)</a></p>
    </div>
    <div style="clear:both;"></div>
  </div>
</div>
<div class="footerArea">
  <div class="container">
    <div class="copyright">&copy; 2012 CPCC - UC Berkeley.</div>
  </div>
</div>
<script type="text/javascript">
		<!--
		var MenuBar1 = new Spry.Widget.MenuBar("MenuBar1", {imgDown:"SpryAssets/SpryMenuBarDownHover.gif", imgRight:"SpryAssets/SpryMenuBarRightHover.gif"});
		//-->
		</script>
</body>
</html>
